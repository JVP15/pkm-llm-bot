{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from tqdm import tqdm\n",
    "\n",
    "from agent_dataset import ReplayDataset, AgentDataset\n",
    "\n",
    "torch.backends.cudnn.tf32 = True\n",
    "\n",
    "seed = 42\n",
    "transformers.set_seed(seed)\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true' # I don't like using wandb for this\n",
    "\n",
    "# Define the tokenizer and model\n",
    "# small model hasn't even had train loss go below val loss\n",
    "MODEL_NAME = 'gpt2-large' # w/ 3 epochs, normal got to ~.174, large ~1.135\n",
    "\n",
    "# action dataset: w/ 2 epochs, normal got to ~.5, large got to ~\n",
    "#MODEL_NAME = 'meta-llama/Llama-2-7b-chat-hf' # try code llama? Probably a better idea b/c it has longer context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining on replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/gen9randombattle\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=32,\n",
    "    fp16=True,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs/gen9randombattle\",\n",
    "    logging_steps=250,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=250,\n",
    "    save_steps=10000,\n",
    "    tf32=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = model.to_bettertransformer()\n",
    "\n",
    "# config = LoraConfig(task_type=TaskType.CAUSAL_LM, r=8, lora_alpha=32, lora_dropout=.1)\n",
    "# model = get_peft_model(model, config)\n",
    "# model.print_trainable_parameters()\n",
    "\n",
    "# Define the dataset collator\n",
    "data_collator = transformers.DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "chunk_size = tokenizer.model_max_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using a dataset of replay files and we'll be learning on the entirety of those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing replays:   0%|          | 0/4320 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Parsing replays: 100%|██████████| 4320/4320 [00:31<00:00, 136.67it/s]\n",
      "Parsing replays: 100%|██████████| 1080/1080 [00:07<00:00, 135.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 18408\n",
      "Validation dataset length: 4612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset\n",
    "data_path = \"dataset/gen9randombattle/replays\"\n",
    "replay_files = [os.path.join(data_path, file) for file in os.listdir(data_path)]\n",
    "\n",
    "random.shuffle(replay_files)\n",
    "train_replay_files = replay_files[:int(len(replay_files) * 0.8)]\n",
    "val_replay_files = replay_files[int(len(replay_files) * 0.8):]\n",
    "\n",
    "train_dataset = ReplayDataset(train_replay_files, tokenizer, chunk_size)\n",
    "val_dataset = ReplayDataset(val_replay_files, tokenizer, chunk_size)\n",
    "\n",
    "print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset length: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1725' max='1725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1725/1725 2:19:59, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.194633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.159974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.149403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.143556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.139636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.136300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1725, training_loss=0.1893086010476817, metrics={'train_runtime': 8406.4879, 'train_samples_per_second': 6.569, 'train_steps_per_second': 0.205, 'total_flos': 2.127190197646848e+17, 'train_loss': 0.1893086010476817, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4612' max='4612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4612/4612 03:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13503998517990112,\n",
       " 'eval_runtime': 224.278,\n",
       " 'eval_samples_per_second': 20.564,\n",
       " 'eval_steps_per_second': 20.564,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = trainer.model.reverse_bettertransformer()\n",
    "trainer.model.save_pretrained(f'models/gen9randombattle_{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning on actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned a general amount of the game, we can fine-tune on the actions of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/gen9randombattle_rating\",\n",
    "    num_train_epochs=3,\n",
    "    #learning_rate=5e-6, # reduce learning rate b/c we've already learned a lot\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=32,\n",
    "    fp16=True,\n",
    "    warmup_steps=0, # we've already learned the format of this text, no need to warmup b/c we're just applying finishing touches\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs/gen9randombattle_rating\",\n",
    "    logging_steps=250,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=250,\n",
    "    save_strategy='no',\n",
    "    tf32=True,\n",
    "    group_by_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'models/gen9randombattle_{MODEL_NAME}')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = model.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing replays: 100%|██████████| 1040/1040 [00:02<00:00, 510.28it/s]\n",
      "Tokenizing actions:   0%|          | 0/1040 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Tokenizing actions: 100%|██████████| 1040/1040 [00:59<00:00, 17.52it/s]\n",
      "Parsing replays: 100%|██████████| 260/260 [00:00<00:00, 604.65it/s]\n",
      "Tokenizing actions: 100%|██████████| 260/260 [00:14<00:00, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 26231\n",
      "Validation dataset length: 6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define the dataset\n",
    "data_path = \"dataset/gen9randombattle_rating/replays\" # this is a high elo dataset\n",
    "replay_files = [os.path.join(data_path, file) for file in os.listdir(data_path)]\n",
    "\n",
    "random.shuffle(replay_files)\n",
    "\n",
    "train_replay_files = replay_files[:int(len(replay_files) * 0.8)]\n",
    "val_replay_files = replay_files[int(len(replay_files) * 0.8):]\n",
    "\n",
    "train_dataset = AgentDataset(train_replay_files, tokenizer, 6) # with a context size of 1024, we can handle about 6 turns\n",
    "val_dataset = AgentDataset(val_replay_files, tokenizer, 6)\n",
    "\n",
    "print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset length: {len(val_dataset)}\")\n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer, padding=False) # don't do any padding right now b/c we have bettertransformers (will change when we use flash attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well it does on the validation set before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6628' max='6628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6628/6628 06:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.45846983790397644,\n",
       " 'eval_runtime': 360.4448,\n",
       " 'eval_samples_per_second': 18.388,\n",
       " 'eval_steps_per_second': 18.388}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2457' max='2457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2457/2457 3:34:21, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.613400</td>\n",
       "      <td>0.575976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.559400</td>\n",
       "      <td>0.545928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.517375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.506219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.496521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.480975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.491288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.353300</td>\n",
       "      <td>0.481597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2457, training_loss=0.45746872140762523, metrics={'train_runtime': 12865.613, 'train_samples_per_second': 6.117, 'train_steps_per_second': 0.191, 'total_flos': 2.74194412362624e+17, 'train_loss': 0.45746872140762523, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6628' max='6628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6628/6628 07:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4847310781478882,\n",
       " 'eval_runtime': 479.0358,\n",
       " 'eval_samples_per_second': 13.836,\n",
       " 'eval_steps_per_second': 13.836,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = trainer.model.reverse_bettertransformer()\n",
    "trainer.model.save_pretrained(f'models/gen9randombattle_rating_{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(f'models/gen9randombattle_{MODEL_NAME}')\n",
    "model.cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_helper(input_text, **kwargs):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to('cuda')\n",
    "    print(input_ids.shape)\n",
    "    if input_ids.shape[-1] > tokenizer.model_max_length:\n",
    "        return None\n",
    "    output = model.generate(input_ids, **kwargs)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"|p1|rating|2397\n",
    "|p2|rating|2401\n",
    "|\n",
    "|start\n",
    "|action|p1|switch|Umbreon\n",
    "|action|p2|switch|Iron Leaves\n",
    "|switch|p1: Umbreon|Umbreon, L85, M|300/300\n",
    "|switch|p2: Iron Leaves|Iron Leaves, L81|278/278\n",
    "|turn|1\n",
    "|action|p1|switch|Banette\n",
    "|action|p2|switch|Sandy Shocks\n",
    "|\n",
    "|-end|p2: Iron Leaves|Quark Drive|[silent]\n",
    "|switch|p2: Sandy Shocks|Sandy Shocks, L80|267/267\n",
    "|switch|p1: Banette|Banette, L93, F|270/270\n",
    "|\n",
    "|upkeep\n",
    "|turn|2\n",
    "|action|p1|switch|Kricketune\n",
    "|action|p2|move|Stealth Rock|tera|null\n",
    "|\n",
    "|switch|p1: Kricketune|Kricketune, L96, M|303/303\n",
    "|move|p2: Sandy Shocks|Stealth Rock|p1: Kricketune\n",
    "|-sidestart|p1|move: Stealth Rock\n",
    "|\n",
    "|upkeep\n",
    "|turn|3\n",
    "|action|p1|move|Sticky Web|tera|null\n",
    "|action|p2|move|Thunderbolt|tera|null\n",
    "|\n",
    "|move|p2: Sandy Shocks|Thunderbolt|p1: Kricketune\n",
    "|-damage|p1: Kricketune|179/303\n",
    "|move|p1: Kricketune|Sticky Web|p2: Sandy Shocks\n",
    "|-sidestart|p2|move: Sticky Web\n",
    "|\n",
    "|upkeep\n",
    "|turn|4\n",
    "|action|p1|move|Pounce|tera|null\n",
    "|action|p2|move|Thunder Wave|tera|null\n",
    "|\n",
    "|move|p2: Sandy Shocks|Thunder Wave|p1: Kricketune\n",
    "|-status|p1: Kricketune|par\n",
    "|move|p1: Kricketune|Pounce|p2: Sandy Shocks\n",
    "|-damage|p2: Sandy Shocks|183/267\n",
    "|-unboost|p2: Sandy Shocks|spe|1\n",
    "|\n",
    "|-heal|p2: Sandy Shocks|199/267|[from] item: Leftovers\n",
    "|upkeep\n",
    "|turn|5\n",
    "|action|p1|move|failed|tera|null\n",
    "|action|p2|move|Thunderbolt|tera|null\n",
    "|\n",
    "|move|p2: Sandy Shocks|Thunderbolt|p1: Kricketune\n",
    "|-damage|p1: Kricketune|41/303 par\n",
    "|cant|p1: Kricketune|par\n",
    "|\n",
    "|-heal|p2: Sandy Shocks|215/267|[from] item: Leftovers\n",
    "|upkeep\n",
    "|turn|6\n",
    "|action|p1|move|failed|tera|null\n",
    "|action|p2|move|Thunderbolt|tera|null\n",
    "|\n",
    "|move|p2: Sandy Shocks|Thunderbolt|p1: Kricketune\n",
    "|-damage|p1: Kricketune|0 fnt\n",
    "|faint|p1: Kricketune\n",
    "|\n",
    "|-heal|p2: Sandy Shocks|231/267|[from] item: Leftovers\n",
    "|upkeep\n",
    "|\n",
    "|action|p1|switch|Breloom\n",
    "|switch|p1: Breloom|Breloom, L82, M|233/233\n",
    "|-damage|p1: Breloom|219/233|[from] Stealth Rock\n",
    "|turn|7\n",
    "|action|p1|\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 863])\n",
      "|p1|rating|2397\n",
      "|p2|rating|2401\n",
      "|\n",
      "|start\n",
      "|action|p1|switch|Umbreon\n",
      "|action|p2|switch|Iron Leaves\n",
      "|switch|p1: Umbreon|Umbreon, L85, M|300/300\n",
      "|switch|p2: Iron Leaves|Iron Leaves, L81|278/278\n",
      "|turn|1\n",
      "|action|p1|switch|Banette\n",
      "|action|p2|switch|Sandy Shocks\n",
      "|\n",
      "|-end|p2: Iron Leaves|Quark Drive|[silent]\n",
      "|switch|p2: Sandy Shocks|Sandy Shocks, L80|267/267\n",
      "|switch|p1: Banette|Banette, L93, F|270/270\n",
      "|\n",
      "|upkeep\n",
      "|turn|2\n",
      "|action|p1|switch|Kricketune\n",
      "|action|p2|move|Stealth Rock|tera|null\n",
      "|\n",
      "|switch|p1: Kricketune|Kricketune, L96, M|303/303\n",
      "|move|p2: Sandy Shocks|Stealth Rock|p1: Kricketune\n",
      "|-sidestart|p1|move: Stealth Rock\n",
      "|\n",
      "|upkeep\n",
      "|turn|3\n",
      "|action|p1|move|Sticky Web|tera|null\n",
      "|action|p2|move|Thunderbolt|tera|null\n",
      "|\n",
      "|move|p2: Sandy Shocks|Thunderbolt|p1: Kricketune\n",
      "|-damage|p1: Kricketune|179/303\n",
      "|move|p1: Kricketune|Sticky Web|p2: Sandy Shocks\n",
      "|-sidestart|p2|move: Sticky Web\n",
      "|\n",
      "|upkeep\n",
      "|turn|4\n",
      "|action|p1|move|Pounce|tera|null\n",
      "|action|p2|move|Thunder Wave|tera|null\n",
      "|\n",
      "|move|p2: Sandy Shocks|Thunder Wave|p1: Kricketune\n",
      "|-status|p1: Kricketune|par\n",
      "|move|p1: Kricketune|Pounce|p2: Sandy Shocks\n",
      "|-damage|p2: Sandy Shocks|183/267\n",
      "|-unboost|p2: Sandy Shocks|spe|1\n",
      "|\n",
      "|-heal|p2: Sandy Shocks|199/267|[from] item: Leftovers\n",
      "|upkeep\n",
      "|turn|5\n",
      "|action|p1|move|failed|tera|null\n",
      "|action|p2|move|Thunderbolt|tera|null\n",
      "|\n",
      "|move|p2: Sandy Shocks|Thunderbolt|p1: Kricketune\n",
      "|-damage|p1: Kricketune|41/303 par\n",
      "|cant|p1: Kricketune|par\n",
      "|\n",
      "|-heal|p2: Sandy Shocks|215/267|[from] item: Leftovers\n",
      "|upkeep\n",
      "|turn|6\n",
      "|action|p1|move|failed|tera|null\n",
      "|action|p2|move|Thunderbolt|tera|null\n",
      "|\n",
      "|move|p2: Sandy Shocks|Thunderbolt|p1: Kricketune\n",
      "|-damage|p1: Kricketune|0 fnt\n",
      "|faint|p1: Kricketune\n",
      "|\n",
      "|-heal|p2: Sandy Shocks|231/267|[from] item: Leftovers\n",
      "|upkeep\n",
      "|\n",
      "|action|p1|switch|Breloom\n",
      "|switch|p1: Breloom|Breloom, L82, M|233/233\n",
      "|-damage|p1: Breloom|219/233|[from] Stealth Rock\n",
      "|turn|7\n",
      "|action|p1|move|Mach Punch|tera|null\n",
      "|action|p2|move|Thunderbolt|tera|null\n",
      "|\n",
      "|move|p1: Breloom|Mach Punch|p2: Sandy Shocks\n",
      "|-resisted|p2: Sandy Shocks\n",
      "|-damage|p2: Sandy Shocks|76/267\n",
      "|-damage|p1: Breloom|219/233|[from] item: Life Orb\n",
      "|move|p2: Sandy Shocks|Thunderbolt|p1: Breloom\n",
      "|-damage|p1: Breloom|0\n"
     ]
    }
   ],
   "source": [
    "print(generate_helper(input_text, max_new_tokens=128, num_beams=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
